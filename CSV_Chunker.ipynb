{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d846dc9-5e1c-4fdc-a0ef-ff0b7d1df034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import os \n",
    "import re \n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f1eb7ee-0b0f-4556-ae4a-620b080a1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_filename(name: str) -> str:\n",
    "    # Replace spaces with underscores\n",
    "    name = name.replace(\" \", \"_\")\n",
    "    # Replace & with 'and'\n",
    "    name = name.replace(\"&\", \"and\")\n",
    "    # Remove unsafe characters (anything not alnum, underscore, dash, or dot)\n",
    "    name = re.sub(r'[^A-Za-z0-9_.\\-]', '_', name)\n",
    "\n",
    "    # If the name is too long, truncate and add a hash suffix\n",
    "    if len(name) > 255:\n",
    "        hash_suffix = hashlib.md5(name.encode(\"utf-8\")).hexdigest()[:8]\n",
    "        truncated = name[:246]  # 246 + 9 = 255\n",
    "        name = f\"{truncated}_{hash_suffix}\"\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79201384-b845-4075-b45d-74bfc7d1063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_csv_by_pdf(input_file: str, output_dir: str, progress_interval: int = 10000):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    writers = {}\n",
    "    files = {}\n",
    "    row_count = 0\n",
    "\n",
    "    with open(input_file, \"r\", encoding=\"utf-8-sig\") as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        headers = reader.fieldnames\n",
    "\n",
    "        for row in reader:\n",
    "            row_count += 1\n",
    "            pdf_name = row[\"pdf_name\"]\n",
    "            safe_name = safe_filename(pdf_name)\n",
    "            output_file = os.path.join(output_dir, f\"{safe_name}.csv\")\n",
    "\n",
    "            # If this pdf_name hasn't been seen before, create a new file + writer\n",
    "            if safe_name not in writers:\n",
    "                f = open(output_file, \"w\", newline=\"\", encoding=\"utf-8\")\n",
    "                writer = csv.DictWriter(f, fieldnames=headers)\n",
    "                writer.writeheader()\n",
    "                writers[safe_name] = writer\n",
    "                files[safe_name] = f\n",
    "\n",
    "            # Write the row to the appropriate file\n",
    "            writers[safe_name].writerow(row)\n",
    "\n",
    "            # Progress indicator\n",
    "            if row_count % progress_interval == 0:\n",
    "                print(f\"Processed {row_count} rows...\")\n",
    "\n",
    "    # Close all files\n",
    "    for f in files.values():\n",
    "        f.close()\n",
    "\n",
    "    print(f\"Finished splitting {input_file} into {len(files)} files in {output_dir}\")\n",
    "    print(f\"Total rows processed: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc44c5ed-af6d-49e3-99d2-73efb8a36671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000 rows...\n",
      "Processed 20000 rows...\n",
      "Processed 30000 rows...\n",
      "Processed 40000 rows...\n",
      "Processed 50000 rows...\n",
      "Processed 60000 rows...\n",
      "Processed 70000 rows...\n",
      "Processed 80000 rows...\n",
      "Processed 90000 rows...\n",
      "Processed 100000 rows...\n",
      "Processed 110000 rows...\n",
      "Processed 120000 rows...\n",
      "Processed 130000 rows...\n",
      "Processed 140000 rows...\n",
      "Processed 150000 rows...\n",
      "Processed 160000 rows...\n",
      "Processed 170000 rows...\n",
      "Processed 180000 rows...\n",
      "Processed 190000 rows...\n",
      "Processed 200000 rows...\n",
      "Processed 210000 rows...\n",
      "Finished splitting C:\\Users\\bhargav\\Downloads\\deep-past-initiative-machine-translation\\publications.csv into 952 files in C:\\chunks_by_pdf\n",
      "Total rows processed: 216602\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "input_file = r\"C:\\Users\\bhargav\\Downloads\\deep-past-initiative-machine-translation\\publications.csv\"\n",
    "chunk_csv_by_pdf(input_file, r\"C:\\chunks_by_pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d6e3de6-0d93-4bb3-97f2-b1c447a0c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def split_into_folders(base_dir: str, max_size_mb: int = 80):\n",
    "    max_size_bytes = max_size_mb * 1024 * 1024\n",
    "\n",
    "    # List all CSV files in the directory\n",
    "    files = [f for f in os.listdir(base_dir) if f.lower().endswith(\".csv\")]\n",
    "\n",
    "    folder_index = 1\n",
    "    current_folder = os.path.join(base_dir, f\"batch_{folder_index}\")\n",
    "    os.makedirs(current_folder, exist_ok=True)\n",
    "    current_size = 0\n",
    "\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(base_dir, filename)\n",
    "        file_size = os.path.getsize(file_path)\n",
    "\n",
    "        # If adding this file would exceed the limit, start a new folder\n",
    "        if current_size + file_size > max_size_bytes:\n",
    "            folder_index += 1\n",
    "            current_folder = os.path.join(base_dir, f\"batch_{folder_index}\")\n",
    "            os.makedirs(current_folder, exist_ok=True)\n",
    "            current_size = 0\n",
    "\n",
    "        # Move the file into the current folder\n",
    "        shutil.move(file_path, os.path.join(current_folder, filename))\n",
    "        current_size += file_size\n",
    "\n",
    "    print(f\"Finished splitting into {folder_index} folders (max {max_size_mb} MB each).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0033d30-dedd-439f-9369-85390a092a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished splitting into 8 folders (max 80 MB each).\n"
     ]
    }
   ],
   "source": [
    "# Run it on your path:\n",
    "split_into_folders(r\"C:\\chunks_by_pdf\", 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
