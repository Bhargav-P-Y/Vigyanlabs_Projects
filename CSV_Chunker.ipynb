{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d846dc9-5e1c-4fdc-a0ef-ff0b7d1df034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import os \n",
    "import re \n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f1eb7ee-0b0f-4556-ae4a-620b080a1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_filename(name: str) -> str:\n",
    "    # Replace spaces with underscores\n",
    "    name = name.replace(\" \", \"_\")\n",
    "    # Replace & with 'and'\n",
    "    name = name.replace(\"&\", \"and\")\n",
    "    # Remove unsafe characters (anything not alnum, underscore, dash, or dot)\n",
    "    name = re.sub(r'[^A-Za-z0-9_.\\-]', '_', name)\n",
    "\n",
    "    # If the name is too long, truncate and add a hash suffix\n",
    "    if len(name) > 255:\n",
    "        hash_suffix = hashlib.md5(name.encode(\"utf-8\")).hexdigest()[:8]\n",
    "        truncated = name[:246]  # 246 + 9 = 255\n",
    "        name = f\"{truncated}_{hash_suffix}\"\n",
    "\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79201384-b845-4075-b45d-74bfc7d1063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_csv_by_pdf(input_file: str, output_dir: str, progress_interval: int = 10000):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    writers = {}\n",
    "    files = {}\n",
    "    row_count = 0\n",
    "\n",
    "    with open(input_file, \"r\", encoding=\"utf-8-sig\") as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        headers = reader.fieldnames\n",
    "\n",
    "        for row in reader:\n",
    "            row_count += 1\n",
    "            pdf_name = row[\"pdf_name\"]\n",
    "            safe_name = safe_filename(pdf_name)\n",
    "            output_file = os.path.join(output_dir, f\"{safe_name}.csv\")\n",
    "\n",
    "            # If this pdf_name hasn't been seen before, create a new file + writer\n",
    "            if safe_name not in writers:\n",
    "                f = open(output_file, \"w\", newline=\"\", encoding=\"utf-8\")\n",
    "                writer = csv.DictWriter(f, fieldnames=headers)\n",
    "                writer.writeheader()\n",
    "                writers[safe_name] = writer\n",
    "                files[safe_name] = f\n",
    "\n",
    "            # Write the row to the appropriate file\n",
    "            writers[safe_name].writerow(row)\n",
    "\n",
    "            # Progress indicator\n",
    "            if row_count % progress_interval == 0:\n",
    "                print(f\"Processed {row_count} rows...\")\n",
    "\n",
    "    # Close all files\n",
    "    for f in files.values():\n",
    "        f.close()\n",
    "\n",
    "    print(f\"Finished splitting {input_file} into {len(files)} files in {output_dir}\")\n",
    "    print(f\"Total rows processed: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc44c5ed-af6d-49e3-99d2-73efb8a36671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10000 rows...\n",
      "Processed 20000 rows...\n",
      "Processed 30000 rows...\n",
      "Processed 40000 rows...\n",
      "Processed 50000 rows...\n",
      "Processed 60000 rows...\n",
      "Processed 70000 rows...\n",
      "Processed 80000 rows...\n",
      "Processed 90000 rows...\n",
      "Processed 100000 rows...\n",
      "Processed 110000 rows...\n",
      "Processed 120000 rows...\n",
      "Processed 130000 rows...\n",
      "Processed 140000 rows...\n",
      "Processed 150000 rows...\n",
      "Processed 160000 rows...\n",
      "Processed 170000 rows...\n",
      "Processed 180000 rows...\n",
      "Processed 190000 rows...\n",
      "Processed 200000 rows...\n",
      "Processed 210000 rows...\n",
      "Finished splitting C:\\Users\\bhargav\\Downloads\\deep-past-initiative-machine-translation\\publications.csv into 952 files in C:\\chunks_by_pdf\n",
      "Total rows processed: 216602\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "input_file = r\"C:\\Users\\bhargav\\Downloads\\deep-past-initiative-machine-translation\\publications.csv\"\n",
    "chunk_csv_by_pdf(input_file, r\"C:\\chunks_by_pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d6e3de6-0d93-4bb3-97f2-b1c447a0c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def split_into_folders(base_dir: str, max_size_mb: int = 80):\n",
    "    max_size_bytes = max_size_mb * 1024 * 1024\n",
    "\n",
    "    # List all CSV files in the directory\n",
    "    files = [f for f in os.listdir(base_dir) if f.lower().endswith(\".csv\")]\n",
    "\n",
    "    folder_index = 1\n",
    "    current_folder = os.path.join(base_dir, f\"batch_{folder_index}\")\n",
    "    os.makedirs(current_folder, exist_ok=True)\n",
    "    current_size = 0\n",
    "\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(base_dir, filename)\n",
    "        file_size = os.path.getsize(file_path)\n",
    "\n",
    "        # If adding this file would exceed the limit, start a new folder\n",
    "        if current_size + file_size > max_size_bytes:\n",
    "            folder_index += 1\n",
    "            current_folder = os.path.join(base_dir, f\"batch_{folder_index}\")\n",
    "            os.makedirs(current_folder, exist_ok=True)\n",
    "            current_size = 0\n",
    "\n",
    "        # Move the file into the current folder\n",
    "        shutil.move(file_path, os.path.join(current_folder, filename))\n",
    "        current_size += file_size\n",
    "\n",
    "    print(f\"Finished splitting into {folder_index} folders (max {max_size_mb} MB each).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0033d30-dedd-439f-9369-85390a092a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished splitting into 8 folders (max 80 MB each).\n"
     ]
    }
   ],
   "source": [
    "# Run it on your path:\n",
    "split_into_folders(r\"C:\\chunks_by_pdf\", 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7b71158-28c7-47a4-89a7-532a651668b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def merge_csvs_in_batches(base_dir: str):\n",
    "    # Find all batch folders inside base_dir\n",
    "    batch_folders = [f for f in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, f)) and f.startswith(\"batch_\")]\n",
    "\n",
    "    for batch in batch_folders:\n",
    "        batch_path = os.path.join(base_dir, batch)\n",
    "        output_file = os.path.join(base_dir, f\"{batch}_merged.csv\")\n",
    "\n",
    "        # Collect all CSV files in this batch folder\n",
    "        csv_files = [f for f in os.listdir(batch_path) if f.lower().endswith(\".csv\")]\n",
    "\n",
    "        if not csv_files:\n",
    "            continue\n",
    "\n",
    "        print(f\"Merging {len(csv_files)} files in {batch} -> {output_file}\")\n",
    "\n",
    "        # Open the output file once\n",
    "        with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "            writer = None\n",
    "\n",
    "            for i, filename in enumerate(csv_files):\n",
    "                file_path = os.path.join(batch_path, filename)\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as infile:\n",
    "                    reader = csv.reader(infile)\n",
    "                    headers = next(reader)\n",
    "\n",
    "                    # Initialize writer with headers from the first file\n",
    "                    if writer is None:\n",
    "                        writer = csv.writer(outfile)\n",
    "                        writer.writerow(headers)\n",
    "\n",
    "                    # Skip headers for subsequent files\n",
    "                    for row in reader:\n",
    "                        writer.writerow(row)\n",
    "\n",
    "        print(f\"Finished {batch}: merged into {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51cd836f-657b-41de-b129-e2cb32704a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging 119 files in batch_1 -> C:\\chunks_by_pdf\\batch_1_merged.csv\n",
      "Finished batch_1: merged into C:\\chunks_by_pdf\\batch_1_merged.csv\n",
      "Merging 80 files in batch_2 -> C:\\chunks_by_pdf\\batch_2_merged.csv\n",
      "Finished batch_2: merged into C:\\chunks_by_pdf\\batch_2_merged.csv\n",
      "Merging 46 files in batch_3 -> C:\\chunks_by_pdf\\batch_3_merged.csv\n",
      "Finished batch_3: merged into C:\\chunks_by_pdf\\batch_3_merged.csv\n",
      "Merging 128 files in batch_4 -> C:\\chunks_by_pdf\\batch_4_merged.csv\n",
      "Finished batch_4: merged into C:\\chunks_by_pdf\\batch_4_merged.csv\n",
      "Merging 226 files in batch_5 -> C:\\chunks_by_pdf\\batch_5_merged.csv\n",
      "Finished batch_5: merged into C:\\chunks_by_pdf\\batch_5_merged.csv\n",
      "Merging 161 files in batch_6 -> C:\\chunks_by_pdf\\batch_6_merged.csv\n",
      "Finished batch_6: merged into C:\\chunks_by_pdf\\batch_6_merged.csv\n",
      "Merging 77 files in batch_7 -> C:\\chunks_by_pdf\\batch_7_merged.csv\n",
      "Finished batch_7: merged into C:\\chunks_by_pdf\\batch_7_merged.csv\n",
      "Merging 115 files in batch_8 -> C:\\chunks_by_pdf\\batch_8_merged.csv\n",
      "Finished batch_8: merged into C:\\chunks_by_pdf\\batch_8_merged.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "merge_csvs_in_batches(r\"C:\\chunks_by_pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
