{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6b3d4b-9787-4451-9fa3-879c49c95e9e",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "Use the `all-MiniLM-L6-v2` model to generate embeddings<br>\n",
    "Leverage a LLM for Q&A tasks<br>\n",
    "Add document upload functionality <br>\n",
    "Employ `FAISS` to retrieve the most semantically similar sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a08d139-a67d-4905-bab8-dc4a7f48bc76",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a9e7f1-dcdb-4ec0-9157-59fd600cc59a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "%pip install -U sentence-transformers\n",
    "%pip install ollama\n",
    "%pip install pdfplumber\n",
    "%pip install python-docx  \n",
    "%pip install nltk\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b75ac236-6825-4637-8491-7dcd4a7a7f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages installed successfully\n"
     ]
    }
   ],
   "source": [
    "if 'ERROR' in output.stdout or 'Failure' in output.stderr:\n",
    "    print('One or more of the package installations failed')\n",
    "    if output.stderr.strip():\n",
    "        print(\"Error details:\\n\", output.stderr.strip())\n",
    "    else:\n",
    "        print(\"Error details:\\n\", output.stdout.strip())\n",
    "else:\n",
    "    print('All packages installed successfully')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0804711c-9b89-4121-be40-9aa383a72f17",
   "metadata": {},
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503b1889-4608-4fd9-8100-c6a258bd9179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bhargav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\bhargav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Contains the model to generate sentence embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# THe local LLM\n",
    "import ollama\n",
    "\n",
    "# For in-memory reading of files\n",
    "from io import BytesIO \n",
    "\n",
    "# To read and extract text from various document types\n",
    "import pdfplumber \n",
    "import docx \n",
    "\n",
    "# To divide text into individual sentences\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk import sent_tokenize \n",
    "\n",
    "# For the File upload functionality\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc63926-d682-4436-a5e0-59092824cb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.2\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "print(faiss.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5698f143-33e9-47a7-b6f9-d31c3b414d0c",
   "metadata": {},
   "source": [
    "### A base dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae86855a-1113-43fb-b606-dd38df7a139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Vigyanlabs is an innovation-driven organization focused on building Intelligent Power Management and Self-Care products to promote green computing and save money for global enterprises.\",\n",
    "    \"Founded in 2008 by Srinivas Varadarajan and Srivatsa Krishnaswamy, Vigyanlabs has attracted top talent to create new intellectual property and deliver sustainable technology solutions.\",\n",
    "    \"The mission of Vigyanlabs is to harness the power of emerging technologies to better manage energy-consuming devices and significantly reduce their overall carbon footprint.\",\n",
    "    \"Vigyanlabs holds over 15 granted US patents related to energy efficiency, data center optimization, and sustainable digital transformation across various enterprise IT infrastructures.\",\n",
    "    \"Headquartered in Mysuru, India, Vigyanlabs operates globally with a presence in major cities like Bangalore, Mumbai, New York, and California to support its international clients.\",\n",
    "    \"The company is recognized as a Microsoft Accelerator incubated startup and has won prestigious accolades like the NASSCOM AI Game Changer and Super Startups Asia awards.\",\n",
    "    \"Vigyanlabs focuses on 'Profitable Sustainability,' a philosophy that ensures environmental initiatives also drive capital and operational cost savings for the businesses that implement them.\",\n",
    "    \"The leadership team at Vigyanlabs brings decades of experience from global technology giants such as HP, Dell, Apple, and various key Indian government technology consulting projects.\",\n",
    "    \"Vigyanlabs played a crucial role in shaping the architecture for Aadhaar 1.0 and has provided strategic technology consulting to the Income Tax Department and India Post.\",\n",
    "    \"With a valuation of approximately 158Cr, Vigyanlabs continues to lead the deep-tech sector by integrating AI-powered sustainability into private and public cloud platforms.\",\n",
    "    \"The flagship product IPM+ is a modular suite covering asset management, patch management, security compliance, endpoint backup, and comprehensive employee productivity monitoring for large organizations.\",\n",
    "    \"IPM+ for Endpoints has seen massive adoption with a deployment base of more than 6 million devices across over 26,000 corporate locations worldwide.\",\n",
    "    \"The standout feature of IPM+ is the US-patented AI PowerMind Engine, which drives energy savings of up to 50 percent per endpoint in real-world deployments.\",\n",
    "    \"Major financial institutions like the State Bank of India and ICICI Lombard rely on the IPM+ suite to manage and optimize their vast device ecosystems.\",\n",
    "    \"IPM+ provides a single pane of glass for enterprises to manage all endpoints, including desktops, laptops, smartphones, and tablets through one unified interface.\",\n",
    "    \"The IPM+ agent is designed with an ultra-light footprint, consuming less than 3 percent of CPU resources to ensure zero performance degradation for end users.\",\n",
    "    \"Vigyanlabs' IPM+ solutions have collectively saved more than 2,000 GWH of energy, demonstrating a significant impact on global sustainability and corporate social responsibility.\",\n",
    "    \"The software includes a certified 'Software Energy Meter' that tracks energy impact with over 90 percent accuracy, as verified by independent global third-party auditors.\",\n",
    "    \"IPM+ allows administrators to enforce over 500 custom policies in real-time, ensuring that security and operational standards are maintained across the entire organization.\",\n",
    "    \"The platform is supported in over 50 countries, providing localized support for diverse IT environments and helping companies reach their global Net-Zero emission targets.\",\n",
    "    \"IPM+ uses patented application sensing technology to optimize power consumption by detecting which software is active and adjusting hardware states accordingly without user intervention.\",\n",
    "    \"The PowerMind AI platform non-intrusively reduces energy consumption across IT infrastructure by managing CPU throttling, GPU performance, and core parking in real-time.\",\n",
    "    \"By lowering heat output from devices, IPM+ helps reduce HVAC cooling costs and UPS capacity requirements by up to 30 percent in office environments.\",\n",
    "    \"Users can extend the battery life of portable devices like laptops and tablets by up to 30 percent using the specialized IPM+ energy assistant modules.\",\n",
    "    \"The solution provides granular control over individual hardware components, including fan speeds, thermal management, and port-level power control to minimize wasted electricity.\",\n",
    "    \"IPM+ provides real-time energy audits and analytics, allowing managers to see exactly how much CO2 emissions have been sequestered through their green computing initiatives.\",\n",
    "    \"The system's adaptive AI/ML power policies are optimized for both Windows and Linux operating systems, ensuring broad compatibility across hybrid enterprise IT fleets.\",\n",
    "    \"Automated power states from S0 to S5 allow devices to transition into low-power modes during periods of inactivity without disrupting background tasks or scheduled updates.\",\n",
    "    \"The IPM+ PowerMind engine is capable of scaling to manage over 250,000 endpoints simultaneously while maintaining fine-grained control over individual user power profiles.\",\n",
    "    \"Strategic power management through IPM+ has saved customers like the State Bank of India over 44 Crore Rupees in annual electricity costs across their branches.\",\n",
    "    \"Vigyanlabs' UEM solution provides a comprehensive management stack that integrates asset tracking, patch deployment, and security enforcement into a single, lightweight software agent.\",\n",
    "    \"The platform offers automated agent-less network discovery to identify all hardware assets, software licenses, and connected peripherals across the entire corporate network.\",\n",
    "    \"IPM+ Asset Management provides life cycle and cost management for IT hardware, helping organizations optimize their capital expenditure by identifying under-utilized or obsolete equipment.\",\n",
    "    \"The system tracks over 200 parameters per endpoint, providing deep insights into device health, performance trends, and potential hardware vulnerabilities before they cause downtime.\",\n",
    "    \"With over 450 built-in dashboards, administrators can monitor security posture, system health, and productivity metrics through a highly customizable and visual analytics interface.\",\n",
    "    \"The UEM suite includes a 'Self-Care' module that allows endpoints to automatically remediate common issues like disk space shortages or system errors using canned scripts.\",\n",
    "    \"Security features in IPM+ include real-time audits of CIS policies, blacklisting of unauthorized applications, and monitoring of firewall and antivirus health across all devices.\",\n",
    "    \"The software provides component-level change management, alerting IT teams immediately if hardware parts like RAM or storage drives are removed or altered.\",\n",
    "    \"IPM+ simplifies the management of distributed workforces by allowing hybrid agents to auto-switch between corporate networks and work-from-anywhere environments while remaining secure.\",\n",
    "    \"The platform's remote remediation capabilities allow IT support teams to fix critical issues on thousands of devices at once without needing physical access to the hardware.\",\n",
    "    \"Vigyanlabs is pioneering the development of India's first Green Micro Data Centers, which use renewable energy and patented cooling technologies to reduce energy consumption.\",\n",
    "    \"The IPM+ Green Cloud offers a next-generation infrastructure with transparent, fixed pricing and a secure Virtual Private Cloud (VPC) environment for every enterprise client.\",\n",
    "    \"Vigyanlabs' micro data centers achieve an unmatched Power Usage Effectiveness score of 1.2, which is significantly better than traditional large-scale hyperscale data centers.\",\n",
    "    \"The IPM+ for Data Center solution provides a unified dashboard that monitors power, cooling, compute, storage, network, and virtualized containers in a single view.\",\n",
    "    \"Vigyanlabs' cloud architecture is reimagined from the ground up as an 'Edge-First' sovereign cloud, reducing enterprise reliance on centralized, energy-intensive IT infrastructure providers.\",\n",
    "    \"The Green Micro DC network is powered by solar energy and features no electrical switches in the building, using 100 percent AI-driven management for high availability.\",\n",
    "    \"Vigyanlabs helps businesses accelerate AI adoption by providing managed cloud platforms that offer one-click deployment for Generative AI and other complex computational workloads.\",\n",
    "    \"The IPM+ Private Cloud solution is a bespoke offering that allows businesses to host Vigyanlabs' cloud architecture on their own physical equipment and on-premises infrastructure.\",\n",
    "    \"By utilizing patented DC optimization technologies, Vigyanlabs can reduce the energy footprint of traditional data centers by up to 50 percent while maintaining 99.9% uptime.\",\n",
    "    \"The 'AI Energy Paradox' is a core principle at Vigyanlabs, suggesting that while AI consumes energy, it can also be the key to saving energy.\",\n",
    "    \"Vigyanlabs offers Industry 4.0 IoT solutions that integrate smart sensors and gateways to monitor factory floors, office buildings, and complex industrial workflows in real-time.\",\n",
    "    \"The Smart Building Solution uses IoT sensors to automate building operations, identify potential equipment failures, and track energy costs across lighting and climate control systems.\",\n",
    "    \"Vigyanlabs provides the world's smallest 'gateway in a box,' which facilitates rapid sensor integration and remote monitoring for diverse industrial and commercial applications.\",\n",
    "    \"The IoT workflow engine allows businesses to set complex rules for automated responses to environmental changes, such as adjusting cooling based on machine load or occupancy.\",\n",
    "    \"Real-time energy audits provided by Vigyanlabs' IoT platform help factories identify 'energy leaks' and optimize production cycles to align with lower-cost energy periods.\",\n",
    "    \"The company's Industry 4.0 solutions are designed for a low Total Cost of Ownership and a quick Return on Investment for manufacturing enterprises.\",\n",
    "    \"Vigyanlabs' IoT stack includes secure data mirroring and synchronization to ensure that critical operational data is always available for analysis and decision-making.\",\n",
    "    \"The platform supports various communication protocols to connect legacy machinery with modern cloud-based monitoring systems for a complete digital transformation of the factory.\",\n",
    "    \"Integrated UPS monitoring through the IPM+ suite provides real-time reporting on backup power health and energy discharge rates during power outages in industrial sites.\",\n",
    "    \"Vigyanlabs continues to innovate in the space of 'Net-Positive' green data centers, where the facility generates more renewable energy than it consumes for its operations.\",\n",
    "    \"IPM+ Employee Productivity Management provides automated timesheets and analyzes application usage hours to help businesses understand workforce engagement and optimize daily operations.\",\n",
    "    \"The productivity module uses AI-driven insights to monitor active versus idle time, helping companies maintain a healthy work culture while ensuring operational efficiency and compliance.\",\n",
    "    \"Vigyanlabs' Patch Management solution automates the deployment of critical updates, ensuring that all endpoints are protected against the latest security vulnerabilities without manual intervention.\",\n",
    "    \"The smart patching engine includes bandwidth throttling to ensure that large software updates do not disrupt network performance for users in bandwidth-constrained remote locations.\",\n",
    "    \"Administrators can pause or schedule patching cycles based on real-time organizational needs, ensuring that updates are only applied during non-critical business hours for each department.\",\n",
    "    \"Detailed patch progress reports provide IT managers with a clear view of which devices are up-to-date and which require immediate attention to remain secure.\",\n",
    "    \"The productivity suite also features print management tools that track paper and cartridge usage, helping enterprises reduce printing costs and environmental waste significantly.\",\n",
    "    \"IPM+ provides actionable intelligence dashboards that combine productivity data with hardware performance to identify correlations between device health and employee output.\",\n",
    "    \"The system's 'AI Help Desk' uses automated diagnostics to resolve user issues faster, reducing the burden on IT support teams and increasing overall organizational uptime.\",\n",
    "    \"Vigyanlabs' employee monitoring tools are designed with privacy and compliance in mind, focusing on high-level productivity trends rather than intrusive individual surveillance.\",\n",
    "    \"Vigyanlabs' products are cybersecurity-compliant and VAPT certified, making them a trusted choice for sensitive environments such as defense, banking, and government infrastructure.\",\n",
    "    \"The IPM+ Policy & Compliance Engine allows for the creation of dynamic groups, where different security policies are automatically applied based on the user's role or location.\",\n",
    "    \"Security features include file and registry monitoring to detect unauthorized system changes that might indicate a malware infection or an attempted data breach.\",\n",
    "    \"The solution monitors the health of existing endpoint security tools like antivirus and firewalls, alerting administrators if these critical defenses are disabled or out-of-date.\",\n",
    "    \"Vulnerability scanning and reporting within IPM+ identify open ports and insecure services, providing a comprehensive risk assessment for the entire enterprise network.\",\n",
    "    \"Vigyanlabs ensures defense-grade security for all its cloud and endpoint solutions, adhering to international standards like CIS benchmarks.\",\n",
    "    \"The IPM+ platform provides non-intrusive security monitoring, ensuring that safety checks do not interfere with the speed or performance of the user's daily tasks.\",\n",
    "    \"Real-time critical patching allows for the immediate deployment of emergency security fixes across the entire organization to mitigate zero-day threats within minutes of discovery.\",\n",
    "    \"The centralized management console provides a secure, encrypted channel for all communication between the IPM+ agents and the cloud-based or on-premises server.\",\n",
    "    \"Vigyanlabs' solutions help enterprises meet their ESG goals by providing auditable data on both energy savings and data security compliance.\",\n",
    "    \"The IPM+ agent is written to be extremely efficient, often consuming less than 10MB of memory and under 3 percent of CPU on a standard business laptop.\",\n",
    "    \"Vigyanlabs utilizes advanced AI algorithms for 'Hyper-Personalized' energy savings, adjusting the power profile of each individual machine based on specific user behavior patterns.\",\n",
    "    \"The platform's architecture is designed for extreme scalability, proven to handle over 100,000 devices distributed across thousands of different geographical locations in a single deployment.\",\n",
    "    \"Software-based energy metering in IPM+ eliminates the need for expensive hardware meters, providing a cost-effective way for companies to measure their IT energy consumption.\",\n",
    "    \"The system includes hardware health management that monitors battery wear levels, fan performance, and operating temperatures to prevent unexpected hardware failures and data loss.\",\n",
    "    \"Vigyanlabs' cloud and data center technologies utilize a software-defined approach, allowing for fully automated management of server resources and environmental controls.\",\n",
    "    \"The IPM+ platform is built for deep insight, analyzing over 200 parameters per endpoint to provide a granular view of the organization's entire digital estate.\",\n",
    "    \"Vigyanlabs' private cloud solution offers true elastic compute capabilities, allowing enterprises to scale their processing power up or down based on real-time demand.\",\n",
    "    \"The system supports DIY reporting and dashboards, enabling users to create custom visualizations of their data without needing any specialized coding or technical skills.\",\n",
    "    \"Vigyanlabs' technology has been validated by PassMark benchmarks, confirming that the software provides maximum efficiency with minimal impact on system performance or storage space.\",\n",
    "    \"The State Bank of India, one of the world's largest banks, has successfully used IPM+ to save over 24.97 GWH of energy annually across its branch network.\",\n",
    "    \"Vigyanlabs' solutions have helped sequestrate thousands of metric tons of CO2 emissions, contributing to the global fight against climate change through smarter IT management.\",\n",
    "    \"Customers using Vigyanlabs' IPM+ have reported cost savings of over $450 million collectively, demonstrating the high financial return on sustainable technology investments.\",\n",
    "    \"Vigyanlabs is listed as a top competitor in the global AI-powered cloud and endpoint management market, frequently cited alongside major international green technology firms.\",\n",
    "    \"The company's products have been featured in several books and academic journals as prime case studies for successful sustainable innovation in the Indian tech ecosystem.\",\n",
    "    \"Vigyanlabs continues to expand its reach, recently raising significant seed funding to further develop its green micro data center network and sovereign AI cloud.\",\n",
    "    \"The partnership between Vigyanlabs and Microsoft has enabled many enterprises to transition their on-premises infrastructure to more energy-efficient, AI-optimized cloud environments.\",\n",
    "    \"Organizations using IPM+ report a 100 percent satisfaction rate due to the software's ability to 'pay for itself' through rapid energy and operational cost savings.\",\n",
    "    \"Vigyanlabs' technology is a key enabler for 'Green IT' departments, providing the tools necessary to measure, report, and reduce the environmental impact of computing.\",\n",
    "    \"As businesses worldwide face increasing pressure to adopt sustainable practices, Vigyanlabs remains at the forefront of the industry with its patented, AI-driven green solutions.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290fc0d-c5f7-49f5-8f47-a98c9114d014",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bdd8a16-75cd-4121-91c0-56ea4a2f9aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "print('Model loaded successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a8e874-f01e-4d34-af01-c8c156589319",
   "metadata": {},
   "source": [
    "### Embedding generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54528a8d-e174-4360-abea-db5ba6681bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(sentences, normalize_embeddings = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5244665f-4035-450c-851c-206d319b8fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 384)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b63b72b5-ad97-4271-8b3d-a987da1d5be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff146fa1-e08b-4b81-b576-b84f9e535b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the embeddings is <class 'numpy.ndarray'>\n",
      "Type of the element inside it is <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print('Type of the embeddings is', type(embeddings))\n",
    "print('Type of the element inside it is', type(embeddings[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1964dad8-7812-4269-aa8d-ea402454e5a1",
   "metadata": {},
   "source": [
    "### Create and populate the FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea6e7400-2abe-416d-90f6-10b56fc0d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the dimension of the vector embedding\n",
    "d = embeddings.shape[1]\n",
    "\n",
    "# Create an index with inner product similarity\n",
    "index = faiss.IndexFlatIP(d)\n",
    "\n",
    "# Populate it\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2cb137-d1d7-4a39-b063-f06056f0e055",
   "metadata": {},
   "source": [
    "### Document upload functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f99fa9a3-4f8d-430c-a3b7-949269d0f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_uploaded_files(uploader_value):\n",
    "    \"\"\"\n",
    "    Takes uploader.value (tuple of dicts), extracts text, splits into sentences,\n",
    "    embeds them, and returns a dict {filename: {\"sentences\": [...], \"embeddings\": [...]}}.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for fileinfo in uploader_value:\n",
    "        name = fileinfo['name']\n",
    "        content = bytes(fileinfo['content'])\n",
    "        ext = name.lower().split('.')[-1]\n",
    "        \n",
    "\n",
    "        # --- Extract text ---\n",
    "        if ext == 'txt':\n",
    "            text = content.decode('utf-8', errors='ignore')\n",
    "\n",
    "        elif ext == 'pdf':\n",
    "            text = \"\"\n",
    "            with pdfplumber.open(BytesIO(content)) as pdf:\n",
    "                for page_num, page in enumerate(pdf.pages, start=1):\n",
    "                    page_text = page.extract_text()\n",
    "                    if page_text:\n",
    "                        text += page_text + \"\\n\"\n",
    "                    print(f\"Page {page_num} length: {len(page_text) if page_text else 0}\")\n",
    "\n",
    "        elif ext == 'docx':\n",
    "            text = \"\"\n",
    "            doc = docx.Document(BytesIO(content))\n",
    "            for para_num, para in enumerate(doc.paragraphs, start=1):\n",
    "                text += para.text + \"\\n\"\n",
    "                if para.text.strip():\n",
    "                    print(f\"Paragraph {para_num} length: {len(para.text)}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"⚠️ Unsupported file type: {ext}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Total extracted text length: {len(text)} characters\")\n",
    "        print(\"Text preview:\", text[:200], \"...\")\n",
    "\n",
    "        # --- Split into sentences ---\n",
    "        sentences = sent_tokenize(text)\n",
    "        print(f\"Number of sentences extracted: {len(sentences)}\")\n",
    "\n",
    "        # --- Embed sentences ---\n",
    "        embeddings = model.encode(sentences, normalize_embeddings=True)\n",
    "        print(\"Embeddings shape:\", embeddings.shape)\n",
    "\n",
    "        # --- Store results ---\n",
    "        results[name] = {\n",
    "            \"sentences\": sentences,\n",
    "            \"embeddings\": embeddings\n",
    "        }\n",
    "\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32b863-ef0f-4b3f-bf8d-e3f98d14899d",
   "metadata": {},
   "source": [
    "### Add the data from the documents to our base dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17dbeb24-a66b-42ef-b1a9-9164f2304278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_context(content):\n",
    "    global sentences, embeddings, index\n",
    "\n",
    "    print(\"Raw uploader content type:\", type(content))\n",
    "\n",
    "    processed = process_uploaded_files(content)\n",
    "    print(\"Processed files:\", list(processed.keys()))\n",
    "\n",
    "    uploaded_sentences = []\n",
    "    uploaded_embeddings = []\n",
    "\n",
    "    for fname, data in processed.items():\n",
    "        print(f\"\\nFile: {fname}\")\n",
    "        uploaded_sentences.extend(data[\"sentences\"])\n",
    "        uploaded_embeddings.extend(data[\"embeddings\"])\n",
    "\n",
    "    # Merge into global lists\n",
    "    sentences.extend(uploaded_sentences)\n",
    "    embeddings = np.vstack([embeddings, uploaded_embeddings])\n",
    "\n",
    "    uploaded_embeddings = np.array(uploaded_embeddings).astype('float32')\n",
    "    index.add(uploaded_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8661650-0473-4aec-924a-01ce4bffc3cc",
   "metadata": {},
   "source": [
    "### Question-Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3acbf762-4977-497e-a513-7ab09be9e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a messages list to store conversations\n",
    "# Added a system message to guide the model's behavior\n",
    "\n",
    "# Messages list\n",
    "messages = [\n",
    "    {'role': 'system', 'content': '''Use uploaded documents as context based on the knowledge base. Answer confidently to the point'''}\n",
    "]\n",
    "\n",
    "def ask_local_llm(query, messages):\n",
    "    print(\"User query:\", query)\n",
    "\n",
    "    query_vec = model.encode([query], normalize_embeddings=True)\n",
    "    print(\"Query embedding shape:\", query_vec.shape)\n",
    "\n",
    "    D, I = index.search(query_vec, k=5)\n",
    "    print(\"Distances:\", D)\n",
    "    print(\"Indices:\", I)\n",
    "\n",
    "    retrieved = []\n",
    "    for idx in I[0]:\n",
    "        if idx < len(sentences):\n",
    "            print(\"Retrieved sentence:\", sentences[idx])\n",
    "            retrieved.append(sentences[idx])\n",
    "        else:\n",
    "            print(\"⚠️ Index out of range:\", idx)\n",
    "\n",
    "    context = \"\\n\".join(retrieved)\n",
    "\n",
    "    if context.strip():\n",
    "        user_msg = f\"Context:\\n{context}\\n\\nQuestion: {query}\"\n",
    "    else:\n",
    "        user_msg = f\"Question: {query}\"\n",
    "\n",
    "    messages.append({'role': 'user', 'content': user_msg})\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='llama3.2',\n",
    "        messages=messages,\n",
    "        options={'temperature': 0}\n",
    "    )\n",
    "\n",
    "    answer = response['message']['content']\n",
    "    messages.append({'role': 'assistant', 'content': answer})\n",
    "\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b590023f-2635-4365-bb5b-fd4abe1cbb72",
   "metadata": {},
   "source": [
    "### Chat Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf056189-b7fb-4fdb-8076-bda351280301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc260928e894f12afa8a6b75b752e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.txt,.pdf,.docx', description='Upload', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8806627ccfce411f97fe32f8b9d79ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Ask:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d48c3275ffb4c4f9f0dabe4cc508e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Ask', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c7e7ddd02c4a30919fd49ebed8bf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create widgets once\n",
    "uploader = widgets.FileUpload(accept='.txt,.pdf,.docx', multiple=True)\n",
    "query_box = widgets.Text(description=\"Ask:\")\n",
    "ask_button = widgets.Button(description=\"Ask\", button_style=\"primary\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Display UI\n",
    "display(uploader, query_box, ask_button, output_area)\n",
    "\n",
    "# Handle file uploads\n",
    "def on_upload_change(change):\n",
    "    if uploader.value:\n",
    "        with output_area:\n",
    "            print(\"User uploaded a doc\")\n",
    "        add_context(uploader.value)   # same structure as before\n",
    "        with output_area:\n",
    "            print(\"Documents uploaded and indexed.\\n\")\n",
    "\n",
    "uploader.observe(on_upload_change, names='value')\n",
    "\n",
    "# Handle queries (only when Ask button is clicked)\n",
    "def run_query(query):\n",
    "    if not query.strip():\n",
    "        return  # ignore empty queries\n",
    "\n",
    "    # Reset messages to just system + current user\n",
    "    local_messages = [messages[0], {'role': 'user', 'content': query}]\n",
    "\n",
    "    answer = ask_local_llm(query, local_messages)\n",
    "    with output_area:\n",
    "        print(f\"Assistant: {answer}\\n\")\n",
    "\n",
    "# Bind only the button click\n",
    "ask_button.on_click(lambda btn: run_query(query_box.value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6100efd-20b9-48e9-a55c-2185615acb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\bhargav'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (faiss)",
   "language": "python",
   "name": "rag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
